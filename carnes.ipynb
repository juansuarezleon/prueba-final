{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fa70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7ed3fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557d624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83452523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0140c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fcaefad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de  C:\\Users\\jksl5\\Desktop\\Clasificador carne\\train\\\n",
      "C:\\Users\\jksl5\\Desktop\\Clasificador carne\\train\\CLASS_02 1\n",
      "C:\\Users\\jksl5\\Desktop\\Clasificador carne\\train\\CLASS_03 62\n",
      "C:\\Users\\jksl5\\Desktop\\Clasificador carne\\train\\CLASS_04 213\n",
      "C:\\Users\\jksl5\\Desktop\\Clasificador carne\\train\\CLASS_05 105\n",
      "C:\\Users\\jksl5\\Desktop\\Clasificador carne\\train\\CLASS_06 949\n",
      "C:\\Users\\jksl5\\Desktop\\Clasificador carne\\train\\CLASS_07 37\n",
      "C:\\Users\\jksl5\\Desktop\\Clasificador carne\\train\\CLASS_08 204\n",
      "Directorios leidos: 7\n",
      "Imagenes en cada directorio [63, 213, 105, 949, 37, 204, 62]\n",
      "suma Total de imagenes en subdirs: 1633\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.join(os.getcwd(), 'train')\n",
    "imgpath = dirname + os.sep \n",
    " \n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    " \n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    " \n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant=cant+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images.append(image)\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant)\n",
    "                prevRoot=root\n",
    "                directories.append(root)\n",
    "                dircount.append(cant)\n",
    "                cant=0\n",
    "dircount.append(cant)\n",
    " \n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e825416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  1633\n",
      "0 CLASS_02\n",
      "1 CLASS_03\n",
      "2 CLASS_04\n",
      "3 CLASS_05\n",
      "4 CLASS_06\n",
      "5 CLASS_07\n",
      "6 CLASS_08\n",
      "Total number of outputs :  7\n",
      "Output classes :  [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
    " \n",
    "carnes=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    carnes.append(name[len(name)-1])\n",
    "    indice=indice+1\n",
    " \n",
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8) #para crear la lista a numpy\n",
    " \n",
    "# Los número de las etiquetas\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d876171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1469, 216, 384, 3) (1469,)\n",
      "Testing data shape :  (164, 216, 384, 3) (164,)\n"
     ]
    }
   ],
   "source": [
    "#Permutación aleatoria entre datos de validación y de test\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.1)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe21e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth : 6')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    " \n",
    "# Cambiar las etiquetas de categorical a one hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Mostrar la primera imagen del entrenamiento en grises\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_Y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "468534b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 6\n",
      "After conversion to one-hot: [0. 0. 0. 0. 0. 0. 1.]\n",
      "(1322, 216, 384, 3) (147, 216, 384, 3) (1322, 7) (147, 7)\n"
     ]
    }
   ],
   "source": [
    "#Mostrar el cambio\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
    " \n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.1, random_state=13)\n",
    " \n",
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d06ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd1ef4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b8afd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9e1b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "carnes_model = Sequential()\n",
    "carnes_model.add(Convolution2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(216,384,3)))\n",
    "carnes_model.add(LeakyReLU(alpha=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41a9b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "carnes_model.add(Flatten())\n",
    "carnes_model.add(Dense(32, activation='linear'))\n",
    "carnes_model.add(LeakyReLU(alpha=0.1))\n",
    "carnes_model.add(Dropout(0.5)) \n",
    "carnes_model.add(Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c8f9351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 216, 384, 32)      896       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 216, 384, 32)      0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2654208)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                84934688  \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,935,815\n",
      "Trainable params: 84,935,815\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "carnes_model.summary()\n",
    " \n",
    "carnes_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(learning_rate=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b675d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 30s 661ms/step - loss: 1.6526 - accuracy: 0.5703 - val_loss: 1.4514 - val_accuracy: 0.5510\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 28s 665ms/step - loss: 1.4315 - accuracy: 0.5794 - val_loss: 1.4555 - val_accuracy: 0.5510\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 27s 653ms/step - loss: 1.4464 - accuracy: 0.5787 - val_loss: 1.4480 - val_accuracy: 0.5510\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 28s 674ms/step - loss: 1.4302 - accuracy: 0.5749 - val_loss: 1.4524 - val_accuracy: 0.5510\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 28s 661ms/step - loss: 1.4330 - accuracy: 0.5802 - val_loss: 1.4525 - val_accuracy: 0.5510\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 29s 680ms/step - loss: 1.4177 - accuracy: 0.5787 - val_loss: 1.4691 - val_accuracy: 0.5510\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 29s 685ms/step - loss: 1.4283 - accuracy: 0.5847 - val_loss: 1.4460 - val_accuracy: 0.5510\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 32s 761ms/step - loss: 1.4267 - accuracy: 0.5832 - val_loss: 1.4424 - val_accuracy: 0.5510\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 38s 894ms/step - loss: 1.4228 - accuracy: 0.5832 - val_loss: 1.4514 - val_accuracy: 0.5510\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 39s 931ms/step - loss: 1.4094 - accuracy: 0.5809 - val_loss: 1.4474 - val_accuracy: 0.5510\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 42s 993ms/step - loss: 1.4183 - accuracy: 0.5817 - val_loss: 1.4689 - val_accuracy: 0.5510\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 28s 658ms/step - loss: 1.4188 - accuracy: 0.5840 - val_loss: 1.4540 - val_accuracy: 0.5510\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 26s 625ms/step - loss: 1.4137 - accuracy: 0.5794 - val_loss: 1.4466 - val_accuracy: 0.5510\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 26s 617ms/step - loss: 1.4266 - accuracy: 0.5855 - val_loss: 1.4461 - val_accuracy: 0.5510\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 26s 621ms/step - loss: 1.4217 - accuracy: 0.5855 - val_loss: 1.4491 - val_accuracy: 0.5510\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 26s 624ms/step - loss: 1.4311 - accuracy: 0.5870 - val_loss: 1.4480 - val_accuracy: 0.5510\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 26s 621ms/step - loss: 1.4015 - accuracy: 0.5885 - val_loss: 1.4544 - val_accuracy: 0.5510\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 26s 618ms/step - loss: 1.4134 - accuracy: 0.5870 - val_loss: 1.4501 - val_accuracy: 0.5510\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 27s 638ms/step - loss: 1.3968 - accuracy: 0.5877 - val_loss: 1.4470 - val_accuracy: 0.5510\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 26s 619ms/step - loss: 1.3952 - accuracy: 0.5885 - val_loss: 1.4569 - val_accuracy: 0.5510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: carnes_mnist.h5py\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: carnes_mnist.h5py\\assets\n"
     ]
    }
   ],
   "source": [
    "carnes_train_dropout = carnes_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    " \n",
    "# guardamos la red para usarla en un futuro, sin la necesidad de volver a entrenar la red.\n",
    "carnes_model.save(\"carnes_mnist.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b533fae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 156ms/step - loss: 1.4466 - accuracy: 0.5488\n",
      "Test loss: 1.4466384649276733\n",
      "Test accuracy: 0.5487805008888245\n"
     ]
    }
   ],
   "source": [
    "test_eval = carnes_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    " \n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3b1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
